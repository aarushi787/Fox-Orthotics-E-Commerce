#!/usr/bin/env node
const fs = require('fs');
const path = require('path');

const OUT_FILE = path.join(__dirname, '..', 'robots.txt');
const baseUrl = process.env.BASE_URL || 'https://yourdomain.com';

const lines = [];
lines.push('# robots.txt generated by scripts/generate-robots.cjs');
lines.push('User-agent: *');
lines.push('Allow: /');
lines.push('');
lines.push(`# Sitemap: ${baseUrl.replace(/\/$/, '')}/sitemap.xml`);
lines.push('');
lines.push('# To block staging or admin paths, add lines like:');
lines.push('# Disallow: /admin/');

try {
  fs.writeFileSync(OUT_FILE, lines.join('\n'));
  console.log(`robots.txt written to ${OUT_FILE}`);
} catch (err) {
  console.error('Failed to write robots.txt', err);
  process.exit(1);
}
